運用大型語言模型（LLMs）於醫療領域時，遭遇的一項主要障礙是 LLMs 使用無法理解的方法來作出臨床決策，這與醫護人員的認知過程大相逕庭。於此手稿中，我們透過開發診斷推理提示研究 LLMs 是否能模仿臨床推理並準確形成診斷。我們發現 GPT-4 能夠被提示以模仿醫護人員常見的臨床推理過程，且不犧牲診斷正確度。這至關重要，因爲一個能模仿臨床推理並提供可理解解釋的大型語言模型，可給予醫師評估其回覆是否正確及值得信賴，進而運用於病患照護。提示方法使用診斷推理有潛力化解 LLMs 的「黑盒子」限制，促使它們更接近安全且有效的使用於醫療領域。

根據專家建議編輯後的翻譯如下：

大型語言模型（LLMs）在醫療領域遇到的主要障礙是它們使用無法理解的方法來做臨床決策，這與醫護人員的認知過程很不同。在這份手稿中，我們透過開發診斷推理提示來研究 LLMs 是否能模仿臨床推理並準確形成診斷。我們發現 GPT-4 能夠被提示以模仿醫護人員常見的臨床推理過程，且不犧牲診斷正確度。這很重要，因為一個能夠模仿臨床推理並提供可理解解釋的 LL